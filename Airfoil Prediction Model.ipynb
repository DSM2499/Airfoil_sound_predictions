{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing warnings generated by your code\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Importing necessary libraries from PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "24/07/12 18:51:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Creating a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Final Project\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n",
      "|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n",
      "|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URL of the dataset\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv'\n",
    "\n",
    "# Downloading the dataset using requests\n",
    "response = requests.get(url)\n",
    "\n",
    "# Writing the content to a CSV file\n",
    "with open('NASA_airfoil_noise_raw.csv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Load the dataset into a Spark DataFrame\n",
    "df = spark.read.csv('NASA_airfoil_noise_raw.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count after dropping duplicates: 1503\n",
      "Row count after dropping missing values: 1499\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows before dropping duplicates\n",
    "rowcount1 = df.count()\n",
    "\n",
    "# Drop duplicate rows\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "# Count the number of rows after dropping duplicates\n",
    "rowcount2 = df.count()\n",
    "print(f\"Row count after dropping duplicates: {rowcount2}\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Count the number of rows after dropping missing values\n",
    "rowcount3 = df.count()\n",
    "print(f\"Row count after dropping missing values: {rowcount3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/12 19:05:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Rename the column 'SoundLevel' to 'SoundLevelDecibels'\n",
    "df = df.withColumnRenamed('SoundLevel', 'SoundLevelDecibels')\n",
    "\n",
    "# Write the cleaned DataFrame to a Parquet file\n",
    "df.write.mode('overwrite').parquet('NASA_airfoil_noise_cleaned.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows = 1522\n",
      "Total rows after dropping duplicate rows = 1503\n",
      "Total rows after dropping duplicate rows and rows with null values = 1499\n",
      "New column name = SoundLevelDecibels\n",
      "NASA_airfoil_noise_cleaned.parquet exists: True\n"
     ]
    }
   ],
   "source": [
    "# Print row counts at different stages of data cleaning\n",
    "print(\"Total rows =\", rowcount1)\n",
    "print(\"Total rows after dropping duplicate rows =\", rowcount2)\n",
    "print(\"Total rows after dropping duplicate rows and rows with null values =\", rowcount3)\n",
    "\n",
    "# Print the new column name to verify the renaming\n",
    "print(\"New column name =\", df.columns[-1])\n",
    "\n",
    "# Import os to check for the existence of the Parquet file\n",
    "import os\n",
    "\n",
    "# Check if the Parquet file exists\n",
    "print(\"NASA_airfoil_noise_cleaned.parquet exists:\", os.path.isdir(\"NASA_airfoil_noise_cleaned.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count after loading Parquet file: 1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/12 19:08:34 WARN Instrumentation: [544119d6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/07/12 19:08:34 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/07/12 19:08:34 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "24/07/12 19:08:35 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/07/12 19:08:35 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset from the Parquet file\n",
    "df = spark.read.parquet('NASA_airfoil_noise_cleaned.parquet')\n",
    "\n",
    "# Count the number of rows in the loaded DataFrame\n",
    "rowcount4 = df.count()\n",
    "print(f\"Row count after loading Parquet file: {rowcount4}\")\n",
    "\n",
    "# Define the stages of the pipeline\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacement'],\n",
    "    outputCol='features'\n",
    ")\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "lr = LinearRegression(featuresCol='features', labelCol='SoundLevelDecibels')\n",
    "\n",
    "# Create a pipeline with the defined stages\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(trainingData, testingData) = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Fit the pipeline model on the training data\n",
    "pipelineModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 26.43369743925488\n"
     ]
    }
   ],
   "source": [
    "# Transform the testing data using the fitted pipeline model\n",
    "predictions = pipelineModel.transform(testingData)\n",
    "\n",
    "# Define the evaluator with mean squared error (MSE) as the metric\n",
    "evaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='SoundLevelDecibels', \n",
    "    metricName='mse'\n",
    ")\n",
    "\n",
    "# Evaluate the predictions and calculate the MSE\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 4.023274015123245\n",
      "R-squared (R2): 0.46038354963983397\n",
      "Intercept: 133.34\n"
     ]
    }
   ],
   "source": [
    "# Define the evaluator with mean absolute error (MAE) as the metric\n",
    "evaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='SoundLevelDecibels', \n",
    "    metricName='mae'\n",
    ")\n",
    "\n",
    "# Evaluate the predictions and calculate the MAE\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Define the evaluator with R-squared (R2) as the metric\n",
    "evaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='SoundLevelDecibels', \n",
    "    metricName='r2'\n",
    ")\n",
    "\n",
    "# Evaluate the predictions and calculate the R2 score\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(f\"R-squared (R2): {r2}\")\n",
    "\n",
    "# Retrieve the LinearRegression model from the pipeline\n",
    "lrModel = pipelineModel.stages[-1]\n",
    "\n",
    "# Print the intercept of the LinearRegression model\n",
    "print(f\"Intercept: {round(lrModel.intercept, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted pipeline model to a directory\n",
    "pipelineModel.write().save(\"Final_Project\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
